{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lFc_wgHSdKqO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from os.path import basename\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "from keras.preprocessing import image \n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import os\n",
        "import string \n",
        "import csv\n",
        "import PIL \n",
        "from PIL import Image\n",
        "from keras import callbacks\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Digits using local dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 119 images belonging to 10 classes.\n",
            "Found 74 images belonging to 10 classes.\n",
            "Epoch 1/500\n",
            "4/4 [==============================] - 4s 450ms/step - loss: 2.5733 - accuracy: 0.1345 - val_loss: 2.4284 - val_accuracy: 0.0946\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 2.2942 - accuracy: 0.1513 - val_loss: 2.3110 - val_accuracy: 0.1081\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 2.2388 - accuracy: 0.1513 - val_loss: 2.2262 - val_accuracy: 0.2297\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 2.1757 - accuracy: 0.2689 - val_loss: 2.1769 - val_accuracy: 0.2703\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 2.0902 - accuracy: 0.3193 - val_loss: 2.1368 - val_accuracy: 0.3108\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 2.0680 - accuracy: 0.3613 - val_loss: 2.1306 - val_accuracy: 0.2973\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 1.9982 - accuracy: 0.3950 - val_loss: 2.0584 - val_accuracy: 0.3649\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 1.9198 - accuracy: 0.5042 - val_loss: 2.0021 - val_accuracy: 0.4324\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 0s 123ms/step - loss: 1.8626 - accuracy: 0.5210 - val_loss: 1.9561 - val_accuracy: 0.4324\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 1.7972 - accuracy: 0.5462 - val_loss: 1.9012 - val_accuracy: 0.4324\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 1.7455 - accuracy: 0.5126 - val_loss: 1.8254 - val_accuracy: 0.4459\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 1.6375 - accuracy: 0.5630 - val_loss: 1.7824 - val_accuracy: 0.4459\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 1.5828 - accuracy: 0.6303 - val_loss: 1.7028 - val_accuracy: 0.5541\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 1.4969 - accuracy: 0.6807 - val_loss: 1.6481 - val_accuracy: 0.5135\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 1.4267 - accuracy: 0.6807 - val_loss: 1.5648 - val_accuracy: 0.5541\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 1.3597 - accuracy: 0.6891 - val_loss: 1.4984 - val_accuracy: 0.6622\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 1.2739 - accuracy: 0.7479 - val_loss: 1.4117 - val_accuracy: 0.5946\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.1929 - accuracy: 0.7563 - val_loss: 1.3259 - val_accuracy: 0.6892\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 1.1259 - accuracy: 0.7479 - val_loss: 1.2483 - val_accuracy: 0.7027\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.9933 - accuracy: 0.8151 - val_loss: 1.2244 - val_accuracy: 0.7297\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.9235 - accuracy: 0.8655 - val_loss: 1.0735 - val_accuracy: 0.7703\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.8471 - accuracy: 0.9244 - val_loss: 0.9743 - val_accuracy: 0.8243\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.7944 - accuracy: 0.9160 - val_loss: 0.8877 - val_accuracy: 0.8649\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.7517 - accuracy: 0.9412 - val_loss: 0.8076 - val_accuracy: 0.9324\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.6712 - accuracy: 0.9244 - val_loss: 0.7626 - val_accuracy: 0.9324\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.5846 - accuracy: 0.9748 - val_loss: 0.7549 - val_accuracy: 0.8784\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.5272 - accuracy: 0.9496 - val_loss: 0.6795 - val_accuracy: 0.8919\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.4822 - accuracy: 0.9832 - val_loss: 0.6858 - val_accuracy: 0.9054\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.4727 - accuracy: 0.9580 - val_loss: 0.5961 - val_accuracy: 0.9054\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.4014 - accuracy: 0.9496 - val_loss: 0.5735 - val_accuracy: 0.8784\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.3995 - accuracy: 0.9748 - val_loss: 0.5030 - val_accuracy: 0.9054\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.3437 - accuracy: 0.9916 - val_loss: 0.4784 - val_accuracy: 0.9324\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.3286 - accuracy: 0.9664 - val_loss: 0.4671 - val_accuracy: 0.9324\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.2895 - accuracy: 0.9916 - val_loss: 0.4190 - val_accuracy: 0.9189\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.3101 - accuracy: 0.9580 - val_loss: 0.4246 - val_accuracy: 0.9189\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.2926 - accuracy: 0.9580 - val_loss: 0.4199 - val_accuracy: 0.9324\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.2746 - accuracy: 0.9748 - val_loss: 0.3230 - val_accuracy: 0.9459\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.2299 - accuracy: 0.9832 - val_loss: 0.3440 - val_accuracy: 0.9189\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.2135 - accuracy: 0.9832 - val_loss: 0.3018 - val_accuracy: 0.9459\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.1827 - accuracy: 0.9916 - val_loss: 0.3204 - val_accuracy: 0.9595\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.1661 - accuracy: 0.9916 - val_loss: 0.3493 - val_accuracy: 0.9189\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.1602 - accuracy: 0.9916 - val_loss: 0.3294 - val_accuracy: 0.9189\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.1709 - accuracy: 0.9832 - val_loss: 0.2842 - val_accuracy: 0.9324\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8919\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.1369 - accuracy: 0.9916 - val_loss: 0.2624 - val_accuracy: 0.9459\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 0s 105ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9324\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.1344 - accuracy: 0.9916 - val_loss: 0.2642 - val_accuracy: 0.9595\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9459\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.1388 - accuracy: 0.9832 - val_loss: 0.2852 - val_accuracy: 0.9189\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1287 - accuracy: 0.9916 - val_loss: 0.2867 - val_accuracy: 0.9459\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1185 - accuracy: 0.9832 - val_loss: 0.2824 - val_accuracy: 0.9459\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.1100 - accuracy: 0.9916 - val_loss: 0.2678 - val_accuracy: 0.9324\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9595\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.1305 - accuracy: 0.9916 - val_loss: 0.2900 - val_accuracy: 0.9459\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9324\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9595\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 0s 105ms/step - loss: 0.0959 - accuracy: 0.9916 - val_loss: 0.1697 - val_accuracy: 0.9595\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9459\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0831 - accuracy: 0.9832 - val_loss: 0.1747 - val_accuracy: 0.9595\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9730\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9595\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 0s 135ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.2109 - val_accuracy: 0.9324\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9865\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0806 - accuracy: 0.9916 - val_loss: 0.2401 - val_accuracy: 0.9595\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.0758 - accuracy: 0.9832 - val_loss: 0.1880 - val_accuracy: 0.9459\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0636 - accuracy: 0.9916 - val_loss: 0.1631 - val_accuracy: 0.9730\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9324\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9189\n"
          ]
        }
      ],
      "source": [
        "training_dir = r\"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Train_ID\\Train\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    width_shift_range=0.02,\n",
        "    height_shift_range=0.02,\n",
        "    #shear_range=0.02,\n",
        "    #zoom_range=0.02,\n",
        "    horizontal_flip= False ,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size = (50,50),\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode = 'categorical'\n",
        "    )\n",
        "\n",
        "model_digits = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (50,50,1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "   #tf.keras.layers.Conv2D(64,(3,3), activation = 'relu' ),\n",
        "   #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "#keras.optimizers.SGD(learning_rate = 0.00001)\n",
        "\n",
        "model_digits.compile(loss = \"categorical_crossentropy\", optimizer = 'adam',\n",
        "       metrics = [\"accuracy\"])\n",
        "\n",
        "validation_dir = r\"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Test_ID\\Test\"\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    width_shift_range=0.02,\n",
        "    height_shift_range=0.02,\n",
        "    #shear_range=0.02,\n",
        "    #zoom_range=0.02,\n",
        "    horizontal_flip= False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size =  (50,50),\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode = 'categorical'\n",
        "    )\n",
        "\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                        mode=\"min\", patience=5,\n",
        "                                       restore_best_weights=True) \n",
        "\n",
        "history = model_digits.fit(\n",
        "    train_generator,\n",
        "    epochs= 500,\n",
        "    shuffle = True,\n",
        "    validation_data = valid_generator,\n",
        "    callbacks=[earlystopping]                                                                                                                                                                                \n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train for Letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14898 images belonging to 26 classes.\n",
            "Found 728 images belonging to 26 classes.\n",
            "Epoch 1/15\n",
            "466/466 [==============================] - 250s 533ms/step - loss: 0.9434 - accuracy: 0.7399 - val_loss: 0.1148 - val_accuracy: 0.9698\n",
            "Epoch 2/15\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 0.3156 - accuracy: 0.9110 - val_loss: 0.1570 - val_accuracy: 0.9505\n",
            "Epoch 3/15\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 0.2335 - accuracy: 0.9327 - val_loss: 0.0546 - val_accuracy: 0.9835\n",
            "Epoch 4/15\n",
            "466/466 [==============================] - 10s 22ms/step - loss: 0.1802 - accuracy: 0.9493 - val_loss: 0.0600 - val_accuracy: 0.9794\n",
            "Epoch 5/15\n",
            "466/466 [==============================] - 11s 24ms/step - loss: 0.1632 - accuracy: 0.9533 - val_loss: 0.0645 - val_accuracy: 0.9835\n",
            "Epoch 6/15\n",
            "466/466 [==============================] - 11s 24ms/step - loss: 0.1418 - accuracy: 0.9576 - val_loss: 0.0382 - val_accuracy: 0.9863\n",
            "Epoch 7/15\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 0.1220 - accuracy: 0.9629 - val_loss: 0.0145 - val_accuracy: 0.9973\n",
            "Epoch 8/15\n",
            "466/466 [==============================] - 11s 25ms/step - loss: 0.1145 - accuracy: 0.9651 - val_loss: 0.1096 - val_accuracy: 0.9643\n",
            "Epoch 9/15\n",
            "466/466 [==============================] - 11s 24ms/step - loss: 0.1029 - accuracy: 0.9683 - val_loss: 0.0175 - val_accuracy: 0.9931\n",
            "Epoch 10/15\n",
            "466/466 [==============================] - 11s 24ms/step - loss: 0.1061 - accuracy: 0.9677 - val_loss: 0.2261 - val_accuracy: 0.9464\n",
            "Epoch 11/15\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 0.0939 - accuracy: 0.9715 - val_loss: 0.0160 - val_accuracy: 0.9973\n",
            "Epoch 12/15\n",
            "466/466 [==============================] - 14s 30ms/step - loss: 0.0877 - accuracy: 0.9733 - val_loss: 0.0062 - val_accuracy: 0.9959\n",
            "Epoch 13/15\n",
            "466/466 [==============================] - 10s 22ms/step - loss: 0.0822 - accuracy: 0.9747 - val_loss: 0.0157 - val_accuracy: 0.9959\n",
            "Epoch 14/15\n",
            "466/466 [==============================] - 11s 23ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 0.0182 - val_accuracy: 0.9959\n",
            "Epoch 15/15\n",
            "466/466 [==============================] - 12s 25ms/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.0037 - val_accuracy: 0.9986\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "\n",
        "training_dir = r\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\archive (1)\\\\data\\\\training_data\"\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size = (50, 50),\n",
        "    class_mode = 'categorical'\n",
        "    )\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu', input_shape = (50, 50,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "       metrics = [\"accuracy\"])\n",
        "validation_dir = r\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\archive (1)\\\\data\\\\testing_data\"\n",
        "valid_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (50, 50),\n",
        "    class_mode = 'categorical'\n",
        "    )\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs= 15,\n",
        "    validation_data=valid_generator\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict Funtion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "F\n",
            "1/1 [==============================] - 0s 435ms/step\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "img1 = cv2.imread(r\"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Image\\main_folders\\folder_0\\subfolder_2\\letter_3.jpg\")\n",
        "img2 = cv2.imread(r\"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Image\\main_folders\\folder_2\\subfolder_0\\letter_1.jpg\")\n",
        "def predict_digits(model, image):\n",
        "    img = cv2.resize(image,(50, 50))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    image_tensor = np.vstack([x])\n",
        "    classes = model.predict(image_tensor)\n",
        "    Alphabet_Mapping_Number_List = list(string.digits)\n",
        "\n",
        "    Max = 0\n",
        "    for i in range(len(classes[0])):\n",
        "        if(Max < classes[0][i]):\n",
        "            Max = classes[0][i]\n",
        "    for i in range(len(classes[0])):\n",
        "        if (Max == classes[0][i]):\n",
        "            return(Alphabet_Mapping_Number_List[i])\n",
        "\n",
        "def predict_letter(model, image):\n",
        "    img = cv2.resize(image,(50,50))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    image_tensor = np.vstack([x])\n",
        "    classes = model.predict(image_tensor)\n",
        "    Alphabet_Mapping_Upper_List = list(string.ascii_uppercase)\n",
        "    Alphabet_Mapping_Lower_List = list(string.ascii_lowercase)\n",
        "    Letter = Alphabet_Mapping_Upper_List \n",
        "\n",
        "    Max = 0\n",
        "    for i in range(len(classes[0])):\n",
        "        if(Max < classes[0][i]):\n",
        "            Max = classes[0][i]\n",
        "    for i in range(len(classes[0])):\n",
        "        if (Max == classes[0][i]):\n",
        "            return(Letter[i])\n",
        "        \n",
        "\n",
        "print(predict_letter(model, img1))\n",
        "print(predict_digits(model_digits, img2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detect Studend card & bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wkdqYSQtdayP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "#from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "class HoughBundler:     \n",
        "    def __init__(self,min_distance=5,min_angle=2):\n",
        "        self.min_distance = min_distance\n",
        "        self.min_angle = min_angle\n",
        "    \n",
        "    def get_orientation(self, line):\n",
        "        orientation = math.atan2(abs((line[3] - line[1])), abs((line[2] - line[0])))\n",
        "        return math.degrees(orientation)\n",
        "\n",
        "    def check_is_line_different(self, line_1, groups, min_distance_to_merge, min_angle_to_merge):\n",
        "        for group in groups:\n",
        "            for line_2 in group:\n",
        "                if self.get_distance(line_2, line_1) < min_distance_to_merge:\n",
        "                    orientation_1 = self.get_orientation(line_1)\n",
        "                    orientation_2 = self.get_orientation(line_2)\n",
        "                    if abs(orientation_1 - orientation_2) < min_angle_to_merge:\n",
        "                        group.append(line_1)\n",
        "                        return False\n",
        "        return True\n",
        "\n",
        "    def distance_point_to_line(self, point, line):\n",
        "        px, py = point\n",
        "        x1, y1, x2, y2 = line\n",
        "\n",
        "        def line_magnitude(x1, y1, x2, y2):\n",
        "            line_magnitude = math.sqrt(math.pow((x2 - x1), 2) + math.pow((y2 - y1), 2))\n",
        "            return line_magnitude\n",
        "\n",
        "        lmag = line_magnitude(x1, y1, x2, y2)\n",
        "        if lmag < 0.00000001:\n",
        "            distance_point_to_line = 9999\n",
        "            return distance_point_to_line\n",
        "\n",
        "        u1 = (((px - x1) * (x2 - x1)) + ((py - y1) * (y2 - y1)))\n",
        "        u = u1 / (lmag * lmag)\n",
        "\n",
        "        if (u < 0.00001) or (u > 1):\n",
        "            #// closest point does not fall within the line segment, take the shorter distance\n",
        "            #// to an endpoint\n",
        "            ix = line_magnitude(px, py, x1, y1)\n",
        "            iy = line_magnitude(px, py, x2, y2)\n",
        "            if ix > iy:\n",
        "                distance_point_to_line = iy\n",
        "            else:\n",
        "                distance_point_to_line = ix\n",
        "        else:\n",
        "            # Intersecting point is on the line, use the formula\n",
        "            ix = x1 + u * (x2 - x1)\n",
        "            iy = y1 + u * (y2 - y1)\n",
        "            distance_point_to_line = line_magnitude(px, py, ix, iy)\n",
        "\n",
        "        return distance_point_to_line\n",
        "\n",
        "    def get_distance(self, a_line, b_line):\n",
        "        dist1 = self.distance_point_to_line(a_line[:2], b_line)\n",
        "        dist2 = self.distance_point_to_line(a_line[2:], b_line)\n",
        "        dist3 = self.distance_point_to_line(b_line[:2], a_line)\n",
        "        dist4 = self.distance_point_to_line(b_line[2:], a_line)\n",
        "\n",
        "        return min(dist1, dist2, dist3, dist4)\n",
        "\n",
        "    def merge_lines_into_groups(self, lines):\n",
        "        groups = []  # all lines groups are here\n",
        "        # first line will create new group every time\n",
        "        groups.append([lines[0]])\n",
        "        # if line is different from existing gropus, create a new group\n",
        "        for line_new in lines[1:]:\n",
        "            if self.check_is_line_different(line_new, groups, self.min_distance, self.min_angle):\n",
        "                groups.append([line_new])\n",
        "\n",
        "        return groups\n",
        "\n",
        "    def merge_line_segments(self, lines):\n",
        "        orientation = self.get_orientation(lines[0])\n",
        "      \n",
        "        if(len(lines) == 1):\n",
        "            return np.block([[lines[0][:2], lines[0][2:]]])\n",
        "\n",
        "        points = []\n",
        "        for line in lines:\n",
        "            points.append(line[:2])\n",
        "            points.append(line[2:])\n",
        "        if 45 < orientation <= 90:\n",
        "            #sort by y\n",
        "            points = sorted(points, key=lambda point: point[1])\n",
        "        else:\n",
        "            #sort by x\n",
        "            points = sorted(points, key=lambda point: point[0])\n",
        "\n",
        "        return np.block([[points[0],points[-1]]])\n",
        "\n",
        "    def process_lines(self, lines):\n",
        "        lines_horizontal  = []\n",
        "        lines_vertical  = []\n",
        "  \n",
        "        for line_i in [l[0] for l in lines]:\n",
        "            orientation = self.get_orientation(line_i)\n",
        "            # if vertical\n",
        "            if 45 < orientation <= 90:\n",
        "                lines_vertical.append(line_i)\n",
        "            else:\n",
        "                lines_horizontal.append(line_i)\n",
        "\n",
        "        lines_vertical  = sorted(lines_vertical , key=lambda line: line[1])\n",
        "        lines_horizontal  = sorted(lines_horizontal , key=lambda line: line[0])\n",
        "        merged_lines_all = []\n",
        "\n",
        "        # for each cluster in vertical and horizantal lines leave only one line\n",
        "        for i in [lines_horizontal, lines_vertical]:\n",
        "            if len(i) > 0:\n",
        "                groups = self.merge_lines_into_groups(i)\n",
        "                merged_lines = []\n",
        "                for group in groups:\n",
        "                    merged_lines.append(self.merge_line_segments(group))\n",
        "                merged_lines_all.extend(merged_lines)\n",
        "                    \n",
        "        return np.asarray(merged_lines_all)\n",
        "\n",
        "def slope(x1,y1,x2,y2):\n",
        "    ###finding slope\n",
        "    if x2!=x1:\n",
        "        return((y2-y1)/(x2-x1))\n",
        "    else:\n",
        "        return 'NA'\n",
        "\n",
        "def drawLine(image,x1,y1,x2,y2):\n",
        "\n",
        "    m=slope(x1,y1,x2,y2)\n",
        "    h,w=image.shape[:2]\n",
        "    if m!='NA':\n",
        "        ### here we are essentially extending the line to x=0 and x=width\n",
        "        ### and calculating the y associated with it\n",
        "        ##starting point\n",
        "        px=0\n",
        "        py=-(x1-0)*m+y1\n",
        "        ##ending point\n",
        "        qx=w\n",
        "        qy=-(x2-w)*m+y2\n",
        "    else:\n",
        "    ### if slope is zero, draw a line with x=x1 and y=0 and y=height\n",
        "        px,py=x1,0\n",
        "        qx,qy=x1,h\n",
        "    cv2.line(image, (int(px), int(py)), (int(qx), int(qy)), (255, 255, 255), 1)\n",
        "\n",
        "def get_contour_areas(contours):\n",
        "    all_areas = []\n",
        "    for cnt in contours:\n",
        "        area= cv2.contourArea(cnt)\n",
        "        all_areas.append(area)\n",
        "    return all_areas\n",
        "\n",
        "def rearrange_points(corners):\n",
        "  # Find center\n",
        "  center = [0]*2\n",
        "  for i in range(corners.shape[0]):\n",
        "    center[0] += corners[i][0][0]\n",
        "    center[1] += corners[i][0][1]\n",
        "  center[0] /= 4\n",
        "  center[1] /= 4\n",
        "\n",
        "  rearranged = [None]*4\n",
        "  for i in range(4):\n",
        "    if corners[i][0][0] < center[0] and corners[i][0][1] > center[1]:\n",
        "      rearranged[i] = 0\n",
        "    elif corners[i][0][0] > center[0] and corners[i][0][1] > center[1]:\n",
        "      rearranged[i] = 1\n",
        "    elif corners[i][0][0] > center[0] and corners[i][0][1] < center[1]:\n",
        "      rearranged[i] = 2\n",
        "    elif corners[i][0][0] < center[0] and corners[i][0][1] < center[1]:\n",
        "      rearranged[i] = 3\n",
        "\n",
        "  corners_copy = [None]*4\n",
        "  for i in range(4):\n",
        "    corners_copy[rearranged[i]] = [corners[i][0].tolist()]\n",
        "  return corners_copy\n",
        "\n",
        "def getWordContours(image):\n",
        "  kernel = np.ones((5,5), np.uint8)\n",
        "  mask = cv2.erode(image, kernel, iterations = 2)\n",
        "  ret,thresh = cv2.threshold(mask,90,255,cv2.THRESH_BINARY_INV)\n",
        "  contours, _ = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "  contours_copy = []\n",
        "  for c in contours:\n",
        "    if cv2.contourArea(c) < 100:\n",
        "      continue\n",
        "    contours_copy.append(c)\n",
        "  return contours_copy\n",
        "\n",
        "def getLetterContours(image):\n",
        "  contours, _ = cv2.findContours(image, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "  return contours\n",
        "\n",
        "def flipBit(image):\n",
        "  copy = np.array(image, copy = True)\n",
        "  for i in range(len(copy)):\n",
        "    for j in range(len(copy[i])):\n",
        "      if copy[i][j] == 255:\n",
        "        copy[i][j] = 0\n",
        "      else:\n",
        "        copy[i][j] = 255\n",
        "  return copy\n",
        "\n",
        "def getImage(image, coor):\n",
        "  return image[coor[1]:coor[1]+coor[3], coor[0]:coor[0]+coor[2]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = cv2.imread(\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Student ID Image Train\\\\im8.jpg\")\n",
        "\n",
        "img_copy = np.array(img, copy = True)\n",
        "\n",
        "# Convert to graycsale\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "# Blur the image for better edge detection\n",
        "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
        "\n",
        "# Canny Edge Detection\n",
        "edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) \n",
        "\n",
        "# Dilate and Gaussian Blur\n",
        "mask = cv2.dilate(edges, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), iterations = 2) \n",
        "mask = cv2.GaussianBlur(mask,(5,5),0)\n",
        "\n",
        "# Find convex hull of contour with largest area\n",
        "contours, _ = cv2.findContours(image=mask, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "page = sorted(contours, key=cv2.contourArea, reverse= True)[0]\n",
        "page = cv2.convexHull(page, False)\n",
        "\n",
        "# Create a binary image with convex hull\n",
        "blank_bin = np.zeros_like(img)\n",
        "cv2.fillPoly(blank_bin, pts =[page], color=(255,255,255))\n",
        "blank_bin = cv2.cvtColor(blank_bin, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Canny Edge Detection and contour again to get the outer line of the convex hull\n",
        "edge_hull = cv2.Canny(image=blank_bin, threshold1=100, threshold2=200)\n",
        "contours, _ = cv2.findContours(image=edge_hull, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "blank_copy = np.zeros_like(img)\n",
        "cv2.drawContours(blank_copy, contours, -1, (255,255,255), 1)\n",
        "\n",
        "# Use HoughLinesP to detect straight lines\n",
        "edge_copy = np.zeros_like(edge_hull)\n",
        "lines = cv2.HoughLinesP(edge_hull, 1, np.pi/180, 60, minLineLength=10, maxLineGap=250)\n",
        "\n",
        "# Combine similar lines, then take 4 longest lines as edges for outer quadrilateral of the image\n",
        "lines = HoughBundler(min_distance=10,min_angle=5).process_lines(lines)\n",
        "length = np.array([[None]*2 for i in range(lines.shape[0])])\n",
        "for i in range(len(length)):\n",
        "  length[i][0] = math.sqrt( (lines[i][0][2]-lines[i][0][0])**2 + (lines[i][0][3] - lines[i][0][1])**2 )\n",
        "  length[i][1] = i\n",
        "length_copy = np.flip(length[length[:,0].argsort()])[:4,0]\n",
        "lines_copy = np.array([None]*4)\n",
        "for i in range(lines_copy.shape[0]):\n",
        "  lines_copy[i] = lines[length_copy[i]]\n",
        "lines = lines_copy\n",
        "\n",
        "# Extends lines, then use goodFeaturesToTrack to get corners of the quadrilateral, after that find its convex hull\n",
        "edge_copy = np.zeros_like(edges)\n",
        "for i in range(4):\n",
        "  drawLine(edge_copy, lines[i][0][0], lines[i][0][1], lines[i][0][2], lines[i][0][3])\n",
        "corners = cv2.convexHull(np.array(cv2.goodFeaturesToTrack(edge_copy,4,0.01,10), dtype = np.int32), False)\n",
        "edge_copy = np.zeros_like(edges)\n",
        "\n",
        "# Fill the convex polygon, find the contours of it\n",
        "cv2.fillPoly(edge_copy, [corners], color = (255,255,255))\n",
        "contours, _ = cv2.findContours(image = edge_copy, mode = cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "# Rearrange and linear transformation to get output cut image\n",
        "output_size = [860, 540]\n",
        "corners = np.float32(rearrange_points(corners))\n",
        "destination = np.float32([[0,output_size[1]], [output_size[0],output_size[1]], [output_size[0],0], [0,0]])\n",
        "matrix = cv2.getPerspectiveTransform(corners, destination)\n",
        "output = cv2.warpPerspective(img_copy, matrix, output_size)\n",
        "\n",
        "# Convert cut to grayscale\n",
        "img = output\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Get cut section of each information section\n",
        "information_coor = [[385, 240, 460, 50], [385, 290, 180, 50], [695, 290, 150, 50], [385, 330, 210, 50], [695, 330, 150, 50], [385, 380, 460, 100], [60, 440, 200, 35]]\n",
        "information_image = [None]*7\n",
        "for i in range(7):\n",
        "  information_image[i] = getImage(gray, information_coor[i])\n",
        "\n",
        "# Get the outer contour of each words\n",
        "information_contours = [None]*7\n",
        "for i in range(7):\n",
        "  information_contours[i] = getWordContours(information_image[i])\n",
        "\n",
        "# Get bounding box of each words\n",
        "word_bounding_box = [[]for _ in range(7)]\n",
        "for i in range(7):\n",
        "  image = np.array(information_image[i], copy = True)\n",
        "  word_bounding_box[i] = [None]*len(information_contours[i])\n",
        "  for c in range(len(information_contours[i])):\n",
        "    word_bounding_box[i][c] = cv2.boundingRect(information_contours[i][c])\n",
        "\n",
        "# Sort by left to right, top to bottom\n",
        "for info in range(len(word_bounding_box)):\n",
        "  y_mean = 0\n",
        "  for box in word_bounding_box[info]:\n",
        "    y_mean += box[1]\n",
        "  y_mean /= len(word_bounding_box[info])\n",
        "  word_bounding_box[info] = sorted(word_bounding_box[info], key=lambda x: x[0])\n",
        "  for i in range(len(word_bounding_box[info])):\n",
        "    if word_bounding_box[info][i][1] > y_mean:\n",
        "      word_bounding_box[info].append(word_bounding_box[info][i])\n",
        "      word_bounding_box[info].pop(i)\n",
        "      i-=1\n",
        "\n",
        "# Get threshold\n",
        "word_image = [[]for _ in range(7)]\n",
        "word_image_thresh = [[]for _ in range(7)]\n",
        "word_image_thresh_mask = [[]for _ in range(7)]\n",
        "for i in range(7):\n",
        "  image = np.array(information_image[i], copy = True)\n",
        "  for c in range(len(information_contours[i])):\n",
        "    word_image[i].append(getImage(information_image[i], word_bounding_box[i][c]))\n",
        "    word_image_thresh[i].append(getImage(information_image[i], word_bounding_box[i][c]))\n",
        "    word_image_thresh_mask[i].append(getImage(information_image[i], word_bounding_box[i][c]))\n",
        "\n",
        "for i in range(len(word_image_thresh)):\n",
        "  for j in range(len(word_image_thresh[i])):\n",
        "    ret,word_image_thresh[i][j] = cv2.threshold(word_image_thresh[i][j],100,255,cv2.THRESH_BINARY_INV)\n",
        "    ret,word_image_thresh_mask[i][j] = cv2.threshold(word_image_thresh_mask[i][j],100,255,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Get a box for every letters\n",
        "word_box = []\n",
        "for i in range(len(word_image_thresh_mask)):\n",
        "  word_box.append([])\n",
        "  for j in range(len(word_image_thresh_mask[i])):\n",
        "    word_box[i].append([])\n",
        "    kernel_horizontal = np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,1,0,0],[0,0,1,0,0],[0,0,1,0,0]])\n",
        "    mask = cv2.filter2D(word_image_thresh_mask[i][j], -1, kernel_horizontal)\n",
        "    for _ in range(20):\n",
        "      mask = cv2.filter2D(mask, -1, kernel_horizontal)\n",
        "    contours = getLetterContours(mask)\n",
        "    box = [None]*len(contours)\n",
        "    for c in range(len(contours)):\n",
        "      box[c] = cv2.boundingRect(contours[c])\n",
        "    box = sorted(box,key=lambda x: x[0], reverse = False)\n",
        "    for c in range(len(contours)):\n",
        "      blank_box = np.zeros((50,50))\n",
        "      box[c] = getImage(word_image_thresh[i][j], box[c])\n",
        "      h,w = box[c].shape\n",
        "      blank_box[int(25-h/2):int(25-h/2)+h, int(25-w/2):int(25-w/2)+w] = box[c][0:h, 0:w]\n",
        "      np.ones((3,3), np.uint8)\n",
        "      blank_box = flipBit(blank_box)\n",
        "      word_box[i][j].append(blank_box)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmClprsTeV7x",
        "outputId": "ca11a3d7-1e2a-42fa-cd15-038e29c4405f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Image\\main_folders' deleted successfully.\n",
            "Directory 'main_folders' created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "folder_path = \"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Image\\main_folders\"\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Folder '{folder_path}' deleted successfully.\")\n",
        "except OSError as e:\n",
        "    print(f\"Error: {folder_path} : {e.strerror}\")\n",
        "\n",
        " # Directory\n",
        "directory = \"main_folders\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"D:\\OneDrive - dsusth\\Study\\B2 Year\\Machine Learning and Data Mining II\\Project\\Image\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "# Create the directory\n",
        "# 'GeeksForGeeks' in\n",
        "# '/home / User / Documents'\n",
        "\n",
        "# Check if directory already exists\n",
        "if not os.path.exists(path):\n",
        "    # Create the directory\n",
        "    os.mkdir(path)\n",
        "    print(\"Directory '%s' created\" % directory)\n",
        "else:\n",
        "    print(\"Directory '%s' already exists\" % directory)\n",
        "\n",
        "# Create subdirectories for i, j, and k\n",
        "for i in range(len(word_box)):\n",
        "    i_folder = os.path.join(path, f\"folder_{i}\")\n",
        "    if not os.path.exists(i_folder):\n",
        "        os.mkdir(i_folder)\n",
        "    for j in range(len(word_box[i])):\n",
        "        j_folder = os.path.join(i_folder, f\"subfolder_{j}\")\n",
        "        if not os.path.exists(j_folder):\n",
        "            os.mkdir(j_folder)\n",
        "        for k in range(len(word_box[i][j])):\n",
        "            letter_path = os.path.join(j_folder, 'letter_{}.jpg'.format(k))\n",
        "            cv2.imwrite(letter_path, word_box[i][j][k])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Return list of information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "['WWWWY WNWW GWW', '25/04/2003', 'WWWW', '2021-2024', 'WMFWWWWW', 'HWWWRW WWNW', 'WN17-160']\n"
          ]
        }
      ],
      "source": [
        "folder = [\"Full_Name\", \"Dob\", \"Gender\", \"Intake\", \"Course\", \"Major\", \"Id\"]\n",
        "list_of_folder = []\n",
        "for i in range(len(word_box)):\n",
        "    if i == 1:\n",
        "        string_folder = \"\"\n",
        "        for j in range(len(word_box[i])):\n",
        "            for k in range(len(word_box[i][j])):\n",
        "                if k == 2 or k == 5:\n",
        "                    string_folder += \"/\"\n",
        "                    continue\n",
        "                img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                string_folder += predict_digits(model_digits, img)\n",
        "        list_of_folder.append(string_folder)\n",
        "    elif i == 3:\n",
        "        string_folder = \"\"\n",
        "        for j in range(len(word_box[i])):\n",
        "            for k in range(len(word_box[i][j])):\n",
        "                if k == 4:\n",
        "                    string_folder += \"-\"\n",
        "                    continue\n",
        "                img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                string_folder += predict_digits(model_digits, img)\n",
        "        list_of_folder.append(string_folder)\n",
        "    elif i == 6:\n",
        "        string_folder = \"\"\n",
        "        for j in range(len(word_box[i])):\n",
        "            for k in range(len(word_box[i][j])):\n",
        "                if k == 0 or k == 1:\n",
        "                    img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                    string_folder += predict_letter(model, img)\n",
        "                elif k == 4:\n",
        "                    string_folder += \"-\"\n",
        "                else:\n",
        "                    img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                    string_folder += predict_digits(model_digits, img)\n",
        "        list_of_folder.append(string_folder)\n",
        "    elif i == 0 or i == 5:\n",
        "        string_folder = \"\"\n",
        "        for j in range(len(word_box[i])):\n",
        "            for k in range(len(word_box[i][j])):\n",
        "                img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                string_folder += predict_letter(model, img)\n",
        "            if j < len(word_box[i]) - 1:\n",
        "                string_folder += \" \"\n",
        "        list_of_folder.append(string_folder)\n",
        "    else:\n",
        "        string_folder = \"\"\n",
        "        for j in range(len(word_box[i])):\n",
        "            for k in range(len(word_box[i][j])):\n",
        "                img = cv2.imread(f\"D:\\\\OneDrive - dsusth\\\\Study\\\\B2 Year\\\\Machine Learning and Data Mining II\\\\Project\\\\Image\\\\main_folders\\\\folder_{i}\\\\subfolder_{j}\\\\letter_{k}.jpg\")\n",
        "                string_folder += predict_letter(model, img)\n",
        "        list_of_folder.append(string_folder)\n",
        "\n",
        "print(list_of_folder)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
